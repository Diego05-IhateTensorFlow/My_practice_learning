{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ecb771",
   "metadata": {},
   "source": [
    "**Ahora intentaré realizar de nuevo una red de regresión con NumPy y TensorFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd8e2564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\Desktop\\functional_api_keras\\myenv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Importación de librerías\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow import GradientTape\n",
    "\n",
    "#Generación de semilla para replicación de datos\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398e547",
   "metadata": {},
   "source": [
    "**Generación de datos artificiales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ab694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.69052570e+00 -4.65937371e-01  3.28201637e-02]\n",
      " [ 4.07516283e-01 -7.88923029e-01  2.06557291e-03]\n",
      " [-8.90385858e-04 -1.75472431e+00  1.01765801e+00]\n",
      " [ 6.00498516e-01 -6.25428974e-01 -1.71548261e-01]\n",
      " [ 5.05299374e-01 -2.61356415e-01 -2.42749079e-01]\n",
      " [-1.45324141e+00  5.54580312e-01  1.23880905e-01]\n",
      " [ 2.74459924e-01 -1.52652453e+00  1.65069969e+00]\n",
      " [ 1.54335535e-01 -3.87139943e-01  2.02907222e+00]\n",
      " [-4.53860299e-02 -1.45067870e+00 -4.05227855e-01]\n",
      " [-2.28831510e+00  1.04939655e+00 -4.16474319e-01]\n",
      " [-7.42553525e-01  1.07247013e+00 -1.65107559e+00]\n",
      " [ 5.35429356e-01 -2.06441480e+00 -6.62159340e-01]\n",
      " [-1.20421985e+00  1.46197563e+00  1.76616088e+00]\n",
      " [-3.29413752e-01  8.40733242e-01 -1.79986401e-01]\n",
      " [ 5.68061887e-01 -7.52837196e-01 -1.70833920e+00]\n",
      " [-1.80309866e+00  3.83121852e-01  2.24759505e+00]\n",
      " [ 2.69411631e-01 -5.24604619e-01  1.91201886e+00]\n",
      " [ 2.37301847e-01  1.01433985e-01  2.52577736e-01]\n",
      " [-1.32377198e-01 -3.09476341e-01 -1.43496347e+00]\n",
      " [ 5.01624123e-01 -9.47754504e-02  1.19308592e+00]\n",
      " [-3.68818468e-01 -1.90636988e+00 -9.96106319e-02]\n",
      " [ 1.69953730e+00 -3.83423123e-01 -8.89856861e-01]\n",
      " [-1.19359192e+00 -1.05001681e+00 -3.00193737e-01]\n",
      " [-1.17998209e+00  1.49763912e+00 -2.82635236e-01]\n",
      " [ 1.08648371e-01  1.43823952e+00  1.50331852e+00]\n",
      " [-2.12732967e-01  3.31974215e-01  7.35026584e-01]\n",
      " [-1.92855460e-01 -1.77801285e+00  6.54705704e-01]\n",
      " [ 8.94352305e-01  4.15502614e-01 -9.23544657e-01]\n",
      " [-1.96027312e-01 -5.90769819e-01 -2.99711237e-01]\n",
      " [ 1.29688519e+00  1.52957963e+00  6.69418193e-01]\n",
      " [ 5.48745120e-01  6.76628990e-01 -1.22421866e-02]\n",
      " [-7.56634615e-02 -6.73645187e-01 -5.58674501e-02]\n",
      " [ 2.25994699e+00  8.69039329e-01 -3.42117023e-01]\n",
      " [-4.71926652e-01 -8.64489992e-01  3.74370350e-01]\n",
      " [ 3.91545694e-01 -1.44312166e+00  4.86335197e-01]\n",
      " [-5.69472271e-01  1.42672116e+00  1.56843984e-01]\n",
      " [ 1.71773005e+00 -4.58126793e-01 -2.87983867e-01]\n",
      " [ 2.99808352e-01  1.05594830e+00  5.65882489e-01]\n",
      " [-1.23352394e+00  1.82900702e-01  2.22447385e-02]\n",
      " [-4.29068594e-01 -6.48105293e-01  1.74757724e+00]\n",
      " [-3.90386481e-01 -8.45922637e-01  6.37112833e-01]\n",
      " [ 1.30622977e-01 -7.58138663e-02  7.81301811e-01]\n",
      " [ 4.88625416e-01  3.62190001e-01  9.64200484e-01]\n",
      " [ 2.83636424e-01 -6.16921949e-01 -3.62282228e-01]\n",
      " [-5.20972335e-01  2.09722057e-01 -1.07798489e+00]\n",
      " [-1.83242597e+00  8.81549246e-02 -1.33652055e+00]\n",
      " [-1.95197810e+00  3.73330784e-01 -7.11053196e-01]\n",
      " [ 4.96125422e-01 -5.30853752e-01 -1.12196239e+00]\n",
      " [-1.24351751e+00 -5.14927223e-01 -2.73382806e-01]\n",
      " [-8.23460084e-01 -2.81107913e-01 -1.53610230e+00]\n",
      " [ 1.44889450e-02 -1.79364874e+00 -1.93856317e-01]\n",
      " [ 6.97294110e-01  1.09193880e+00  1.71438025e+00]\n",
      " [-1.55628765e+00  7.58725201e-01  1.20628219e+00]\n",
      " [ 9.80556985e-01 -9.29323815e-01  4.11796831e-01]\n",
      " [ 1.86005567e+00 -1.49727364e+00  4.76337700e-01]\n",
      " [ 1.11229049e+00 -6.96591016e-01  5.82970303e-01]\n",
      " [-1.07089251e+00 -8.12208581e-01 -8.17080247e-01]\n",
      " [ 1.92307699e-01 -9.09812660e-02  9.54115208e-01]\n",
      " [-9.40279114e-01 -1.31275650e-01  9.61076464e-01]\n",
      " [ 5.60777172e-01 -1.32464134e+00  6.65203685e-01]\n",
      " [-4.78417880e-01  3.85386538e-01  3.00680415e-01]\n",
      " [ 1.21931888e+00  1.16559940e-01 -1.85380587e+00]\n",
      " [-1.36985972e+00  7.31154385e-01 -2.58316333e-01]\n",
      " [ 1.13797906e+00  2.73438818e-01 -7.49065736e-01]\n",
      " [ 1.08240676e+00 -8.07397682e-01 -2.05263551e+00]\n",
      " [ 2.06379555e+00 -1.91074888e+00  6.36412859e-01]\n",
      " [ 9.38851769e-01  1.47065863e-01 -1.68339684e+00]\n",
      " [ 1.01501494e+00 -1.44154372e+00 -1.34362856e+00]\n",
      " [-3.61668313e-01  7.88504574e-01  3.00113906e-01]\n",
      " [ 8.10768286e-01 -4.43643831e-01 -1.72183287e-01]\n",
      " [-1.13713679e+00 -3.16865453e-01  5.93128152e-01]\n",
      " [-2.99828054e-01  4.75459555e-01 -5.73274252e-01]\n",
      " [-5.92391593e-01  3.91686497e-02 -1.94881503e-01]\n",
      " [ 5.92385243e-01  1.78290242e-01  1.74034630e+00]\n",
      " [-2.19494505e-01 -2.27252650e-01 -1.04013106e+00]\n",
      " [ 2.27779674e-02  6.82828939e-01 -7.40295641e-01]\n",
      " [-4.96722628e-02  7.18556760e-01 -1.26909149e-01]\n",
      " [-5.19137301e-01  9.73093151e-01  9.70195656e-02]\n",
      " [ 3.96564506e-01  1.17139345e+00  1.14531592e+00]\n",
      " [-3.47204182e-01 -5.25429719e-01  2.84308933e-01]\n",
      " [-1.32787535e-01 -1.89986132e+00  1.27536173e+00]\n",
      " [ 1.93613275e-02  7.36377967e-01 -1.17291656e+00]\n",
      " [ 1.28820356e+00 -5.88262806e-01 -1.07667073e-01]\n",
      " [-1.40142467e+00 -1.66949737e-01 -2.29803933e-01]\n",
      " [-1.85360539e-01  4.38504743e-01  6.03458479e-02]\n",
      " [ 9.75782625e-01 -4.68158186e-01 -9.96015909e-01]\n",
      " [-1.91063916e-02  6.28368036e-01  1.24464177e+00]\n",
      " [ 8.13921436e-01 -1.76544067e+00  3.77058358e-01]\n",
      " [ 1.46037177e+00  6.25763663e-02 -5.16042500e-01]\n",
      " [ 3.09160853e-01 -5.03241984e-01  6.39113166e-01]\n",
      " [-1.29944715e-02  1.39300013e+00  4.99502748e-01]\n",
      " [-7.23884687e-01  6.04631284e-01  9.36011700e-01]\n",
      " [-5.68455855e-01 -4.25794402e-01 -2.30518327e+00]\n",
      " [ 9.03405989e-01 -5.87754384e-01 -2.12234947e+00]\n",
      " [-1.76877170e+00 -2.22950156e-01  7.60659970e-01]\n",
      " [-8.90646188e-02  4.71777759e-01 -1.10149963e+00]\n",
      " [-1.34136563e+00  8.85720807e-01  4.92144459e-01]\n",
      " [-3.05088499e-02  1.28209263e+00 -9.51190458e-01]\n",
      " [-4.20266322e-01  1.02637133e+00  1.83779439e+00]\n",
      " [ 8.42559997e-03  1.67951941e+00 -6.02510615e-01]]\n"
     ]
    }
   ],
   "source": [
    "#Las filas del array son ejemplos de entrenamiento y las columnas son las características de ese ejemplo de entrenamiento\n",
    "X = np.random.randn(100, 3) #Generación de 100 datos con 3 características\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb14128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Revisamos la forma de X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163e3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora generamos las predicciones relativas, aunque para meterle un poco más de realismo a los datos,usaré un ruido gaussiano\n",
    "\n",
    "#Generación de los resultados de la función x^2 + 3\n",
    "Y_before = X ** 2 + 3\n",
    "\n",
    "#Generación de ruido gaussiano\n",
    "noise = np.random.randn(len(X)) * 0.7 #Este parámetro controla que tan disperso quiero los datos\n",
    "noise = noise.reshape(100, 1) #Acá se hace un reshape, porque Python se pone gracioso con sus arrays de la forma (n,)\n",
    "\n",
    "#Sumamos los resultados el ruido gaussiano\n",
    "Y_noisy = Y_before + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c615e",
   "metadata": {},
   "source": [
    "**Ahora revisamos el mapa de dispersión de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d16d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(X, Y_noisy, \".b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d9fa06",
   "metadata": {},
   "source": [
    "**Se ven bien, aunque muy dispersos, pero si desean ajustar el parámetro que les mencioné anteriormente (0.7) a un número < 0.7 les dará datos menos dispersos, ahora realizaré una implementación de Keras con TensorFlow y un poco de NumPy, toda la lógica serán matemáticas puras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b65ba1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelo_reg():\n",
    "    #Generación del diccionario de pesos (parecido al diccionario stat_dict) y el optimizador ADAM con un lr de 1e-4\n",
    "    def __init__(self):\n",
    "        self.weights_bias = {};\n",
    "        self.optimizer = RMSprop(1e-2)\n",
    "\n",
    "    #Método de la clase para realizar la obtención del último dígito de la capa\n",
    "    def get_last_layer_num(self):\n",
    "        #Revisamos si el diccionario contiene algún elemento\n",
    "        if self.weights_bias:\n",
    "            \"\"\"Si el diccionario tiene elementos, convertimos a una lista las claves de su diccionario y con [-1] \n",
    "            obtenemos el último elemento\"\"\"\n",
    "            last_key = list(self.weights_bias.keys())[-1]\n",
    "\n",
    "            #Una vez obtenemos el último elemento \"layerx\", obtenemos el string \"x\" y lo convertimos a entero, donde x es el número de la capa\n",
    "            return int(last_key[-1])\n",
    "        else:\n",
    "            #Si no hay elemento devolvemos 0 porque la lógica del sig. numero es n + 1\n",
    "            return 0\n",
    "    \n",
    "    def input_shape(self, data):\n",
    "        #Aquí intenté realizar la lógica de la capa de entrada de Keras\n",
    "        if isinstance(data, np.ndarray): #Revisa si el dato pasado es un array de NumPy\n",
    "            self.data = data #Se crea una instancia del objeto\n",
    "        else:\n",
    "            #Realizamos el control de error\n",
    "            raise Exception(\"Input must be a numpy array!\")\n",
    "\n",
    "    def add(self, neurons):\n",
    "        #GEN DE PESOS Y BIAS\n",
    "        last_number = self.get_last_layer_num()\n",
    "        next_number = last_number + 1 #Aquí es donde mencioné que se aplicaba la lógica de n + 1\n",
    "\n",
    "        #Revisamos la forma de la capa anterior, para obtener la forma de la capa siguiente\n",
    "        if not self.weights_bias:\n",
    "            #Si no hay ningún elemento, obtenemos la forma anterior de los datos de entrada\n",
    "            input_shape = self.data.shape[1]\n",
    "        else:\n",
    "            #Si hay algún elemento, obtenmos los strings de los pesos y capa para pasarlos al diccionario y obtener la forma del anterior\n",
    "            prev_w = f\"W{last_number}\"\n",
    "            prev_layer = f\"layer{last_number}\"\n",
    "            input_shape = self.weights_bias[prev_layer][prev_w].shape[1]\n",
    "\n",
    "        #Generación de he_uniform\n",
    "        limite = np.sqrt(6 / input_shape)\n",
    "\n",
    "        #Una vez obtenemos la forma de la capa anterior, realizamos la creación de los pesos y sesgos de la siguiente capa\n",
    "        self.weights_bias[f\"layer{next_number}\"] = {\n",
    "            f\"W{next_number}\" : tf.Variable(np.random.uniform(low = -limite, high= limite, size = (input_shape, neurons)).astype(np.float32)), \n",
    "            f\"b{next_number}\" : tf.Variable(np.zeros((neurons,)).astype(np.float32)) \n",
    "    \n",
    "        }\n",
    "        \"\"\"Es más reoomendable empezar en 0 los sesgos para que la red se enfoque primero en los pesos, por si se preguntan, \n",
    "            no causa problemas de simetería porque son los pesos los que realmente deben ser aleatorios para evitar que la red no aprenda porque sin\n",
    "            gradientes no hay aprendizaje automático ☝️🤓\"\"\"\n",
    "\n",
    "    #Realizamos el método fit de Keras muy abstracto\n",
    "    def fit(self, data_in, epochs):\n",
    "        if self.weights_bias:\n",
    "            #Una vez revisamos que el usuario haya declarado capas, realizamos las vueltas por epoch\n",
    "            for i in range(epochs):\n",
    "                #Pasamos como inpút los datos X\n",
    "                input_ = tf.convert_to_tensor(data_in[0], dtype=np.float32)\n",
    "\n",
    "                #Uso de GradientTape() para evitar calcular y calcular los gradientes manualmente con funciones en el backpropagatoon\n",
    "                with GradientTape() as tape:\n",
    "\n",
    "                    #Aquí realizamos el forward pass yendo capa x capa\n",
    "                    for layer in self.weights_bias:\n",
    "\n",
    "                            #Obtenemos los pesos y sesgos\n",
    "                            W = self.weights_bias[layer][\"W\"+layer[-1]]\n",
    "                            B = self.weights_bias[layer][\"b\"+layer[-1]] \n",
    "\n",
    "                            #Realizamos la lógica de MLPs donde primero se calcula una función lineal de la forma W*X + B\n",
    "                            z = tf.matmul(input_, W) + B #(100, 3) * (100, 64)\n",
    "                            #Después de la función lineal, ocupamos una función de activación que son funciones no lineales para romper la simetría de los pesos y sesgos para aprender cosas más complejas\n",
    "                            a = tf.nn.leaky_relu(z, alpha=0.1)\n",
    "\n",
    "                            #Retornamos la variable A que es la salida de la capa\n",
    "                            input_ = a\n",
    "                    \n",
    "                    #Calculamos la función de coste (que es una función de perdida, pero de todos los datos) para obtener el error\n",
    "                    loss = tf.reduce_mean(tf.square(tf.convert_to_tensor(data_in[1], dtype=np.float32) - a))\n",
    "\n",
    "                    # -- Pasos para la regularización L2 o Ridge mejor dicho xd ---\n",
    "\n",
    "                    # Fórmula pa: total_loss = loss + lambda / 2 * sum(l2_loss) asd\n",
    "\n",
    "                    # 1. Definir el hiperparámetro de regularización (lambda)\n",
    "                    l2_lambda = 1e-4\n",
    "\n",
    "                    # 2. Calcular el término de regularización L2\n",
    "                    l2_loss = 0.0\n",
    "                    for layer in self.weights_bias:\n",
    "                        # Sumar el cuadrado de los pesos de cada capa\n",
    "                        W = self.weights_bias[layer][\"W\" + layer[-1]]\n",
    "                        l2_loss += tf.reduce_sum(tf.square(W)) #Acá axis es igual a 0, por flas pa\n",
    "                    \n",
    "                    # 3. Sumar la pérdida de regularización a la pérdida original\n",
    "                    total_loss = loss + (l2_lambda / 2) * l2_loss\n",
    "                    \n",
    "                    #Realizamos la lógica para que solo imprima el error cuando sea la capa 10, 20, 30, etc. Para evitar mucho texto en la salida.\n",
    "                    if i % 10 == 0:\n",
    "                        print(total_loss)\n",
    "\n",
    "                    #Generamos la lista donde pondremos los pesos y sesgos sin que sea un diccionario de Python\n",
    "                    variables = []\n",
    "\n",
    "                    #Obtención de la lista de pesos y sesgos\n",
    "                    for layer in self.weights_bias:\n",
    "                        variables.extend(list(self.weights_bias[layer].values())) #Usamos extend() porque append() no es para objetos iterables y extend() si\n",
    "                    gradientes = tape.gradient(total_loss, variables) # Calculamos los gradientes de la pérdida con respecto a los pesos y sesgos\n",
    "\n",
    "                    #Modificamos los pesos y sesgos en base a su gradiente, donde la forma matemática es: \"W: W_anterior - lr * dw/dL\"\n",
    "                    self.optimizer.apply_gradients(zip(gradientes, variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f16b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de la instancia del modelo\n",
    "modelo = modelo_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7eaeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generación de las capas\n",
    "\n",
    "modelo.input_shape(X)\n",
    "modelo.add(64)\n",
    "modelo.add(64)\n",
    "modelo.add(32)\n",
    "modelo.add(32)\n",
    "modelo.add(16)\n",
    "modelo.add(8)\n",
    "modelo.add(4)\n",
    "modelo.add(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a337a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer1': {'W1': <tf.Variable 'Variable:0' shape=(3, 64) dtype=float32, numpy=\n",
       "  array([[ 1.2064337 , -0.09189934,  0.23441488, -0.77346265, -0.7286078 ,\n",
       "           0.06254273, -0.76592404, -1.3286457 , -0.3721985 ,  0.7069516 ,\n",
       "          -0.6305407 ,  1.0258816 ,  0.57276326,  0.43365192,  1.1101099 ,\n",
       "          -1.2054445 , -0.90858865,  1.157591  ,  1.1512755 , -1.1928403 ,\n",
       "           0.77564394, -1.3705641 , -1.0317097 , -1.1037638 , -0.5826685 ,\n",
       "          -0.31602463,  1.1621268 , -0.17989415, -1.0639155 , -0.643895  ,\n",
       "          -1.3961772 , -1.3348778 , -0.19496822,  0.03447363, -0.7072154 ,\n",
       "          -0.33971554, -1.1218419 ,  0.4492152 , -0.3037573 , -0.9573502 ,\n",
       "          -0.00737192, -0.8248405 , -0.5879472 , -1.0630065 ,  0.7940257 ,\n",
       "          -0.6241908 ,  1.2888482 , -0.26747894, -0.9752573 ,  0.5804299 ,\n",
       "           0.6606022 ,  1.0785348 , -1.0422401 ,  0.8199213 ,  1.0175524 ,\n",
       "          -0.55290574, -0.12874383,  0.33839858, -0.71979755,  1.0503532 ,\n",
       "           0.5634064 ,  1.008852  , -0.14166163,  0.05373548],\n",
       "         [-0.864779  , -0.5260185 ,  0.6491584 ,  1.2982701 , -0.9840017 ,\n",
       "          -1.270972  , -1.2234286 , -0.1825134 ,  0.8277994 , -0.77816457,\n",
       "          -0.06468027,  0.04356395,  0.95516664, -0.9502576 , -1.372583  ,\n",
       "           0.01882327, -0.40942636, -0.5878451 ,  0.7700028 ,  0.5189232 ,\n",
       "          -1.1768035 ,  0.13605686,  0.8424318 ,  1.1587623 , -1.4136906 ,\n",
       "           0.86988306, -1.2918899 ,  0.5151148 ,  0.27720594,  1.2784952 ,\n",
       "           0.3730104 , -1.216396  ,  0.48195827, -0.69318974,  0.9388794 ,\n",
       "          -1.3252254 , -0.497419  ,  0.49903604, -0.9740119 ,  0.4137197 ,\n",
       "           0.557836  ,  0.6612231 ,  1.0616082 , -0.24560331, -1.0112108 ,\n",
       "          -0.67794305, -0.31201681, -1.2598449 ,  0.58986515, -1.2359926 ,\n",
       "          -1.2509886 ,  1.2232934 ,  0.8661941 , -0.6966952 , -0.44771713,\n",
       "           0.92184013,  0.33724883, -0.6649134 , -0.14419548,  1.0056744 ,\n",
       "          -1.4122581 ,  1.3927002 ,  0.1864882 , -0.89938307],\n",
       "         [ 0.84907347, -1.198701  , -0.2545582 ,  0.20684928, -0.71504235,\n",
       "           1.089603  ,  0.55690044, -0.95649445, -0.982597  , -1.23904   ,\n",
       "           0.20222834, -0.88454247,  0.12157337,  0.9036046 ,  1.0724972 ,\n",
       "          -1.0851251 , -0.4745042 , -0.23369676, -0.32974517, -0.22958638,\n",
       "          -0.11317249,  0.7256338 , -0.5500844 , -0.44286287, -0.31043476,\n",
       "          -0.9865031 ,  0.36875176, -0.28214684,  1.1770573 ,  0.90910137,\n",
       "          -0.7631665 , -0.72884613,  0.7983818 ,  0.1693859 , -1.3853333 ,\n",
       "           0.36736473, -0.29723117,  0.80670637,  0.69818884,  1.194524  ,\n",
       "           0.56366587,  1.1680799 , -0.6090881 , -0.45618093, -1.2467682 ,\n",
       "           1.037852  , -0.97802037,  0.14515351,  0.02600849,  0.8879425 ,\n",
       "          -0.31681362, -1.0106969 , -0.33069673, -1.2783077 , -0.56152815,\n",
       "           0.3677032 , -1.2525884 ,  1.3850701 ,  0.1023582 , -0.5654822 ,\n",
       "           0.94409287, -1.0254033 , -0.5035619 ,  1.236447  ]],\n",
       "        dtype=float32)>,\n",
       "  'b1': <tf.Variable 'Variable:0' shape=(64,) dtype=float32, numpy=\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>},\n",
       " 'layer2': {'W2': <tf.Variable 'Variable:0' shape=(64, 64) dtype=float32, numpy=\n",
       "  array([[-0.15925781,  0.1426166 , -0.2566267 , ...,  0.08348095,\n",
       "           0.14865728, -0.02558289],\n",
       "         [ 0.2159222 ,  0.04360839,  0.23380992, ...,  0.15917616,\n",
       "          -0.16511607, -0.2746572 ],\n",
       "         [-0.28818175, -0.20801328, -0.16058426, ..., -0.13120885,\n",
       "           0.05678894,  0.03213412],\n",
       "         ...,\n",
       "         [-0.27152157, -0.11172293, -0.135358  , ..., -0.06766891,\n",
       "          -0.20425282,  0.10840285],\n",
       "         [ 0.00783632,  0.07779664, -0.03601598, ..., -0.14424342,\n",
       "          -0.13816015,  0.09229955],\n",
       "         [ 0.21249159, -0.05562501, -0.30563426, ..., -0.2101952 ,\n",
       "          -0.03538473, -0.18756063]], shape=(64, 64), dtype=float32)>,\n",
       "  'b2': <tf.Variable 'Variable:0' shape=(64,) dtype=float32, numpy=\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>},\n",
       " 'layer3': {'W3': <tf.Variable 'Variable:0' shape=(64, 32) dtype=float32, numpy=\n",
       "  array([[-0.04645327, -0.28737515, -0.13890843, ...,  0.12927173,\n",
       "          -0.19969763,  0.1205214 ],\n",
       "         [ 0.11652704,  0.10632161,  0.2826079 , ..., -0.2267413 ,\n",
       "          -0.11567308, -0.25758636],\n",
       "         [-0.20993128, -0.22163199, -0.10548997, ...,  0.2529681 ,\n",
       "           0.00278775,  0.14180851],\n",
       "         ...,\n",
       "         [-0.17115474, -0.16535242,  0.07936081, ..., -0.13232206,\n",
       "          -0.2358605 , -0.01973401],\n",
       "         [ 0.00853754, -0.29159713,  0.11711206, ..., -0.09342548,\n",
       "           0.13019292, -0.13319202],\n",
       "         [ 0.24474563, -0.20544612,  0.18095902, ..., -0.01509916,\n",
       "           0.14621983,  0.13761766]], shape=(64, 32), dtype=float32)>,\n",
       "  'b3': <tf.Variable 'Variable:0' shape=(32,) dtype=float32, numpy=\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        dtype=float32)>},\n",
       " 'layer4': {'W4': <tf.Variable 'Variable:0' shape=(32, 32) dtype=float32, numpy=\n",
       "  array([[ 2.93809474e-01, -2.01287463e-01,  2.27435365e-01, ...,\n",
       "          -3.75838429e-01,  2.93112129e-01, -2.44932696e-01],\n",
       "         [-1.17227279e-01,  2.89993525e-01,  1.14512764e-01, ...,\n",
       "           2.81337738e-01, -3.62913221e-01,  3.06662947e-01],\n",
       "         [ 3.38682801e-01,  9.16150585e-02, -1.61155030e-01, ...,\n",
       "          -1.45946831e-01,  3.74590717e-02, -2.09400296e-01],\n",
       "         ...,\n",
       "         [ 1.02034993e-01,  9.37435701e-02,  1.64879829e-01, ...,\n",
       "          -3.78606409e-01,  4.20931846e-01, -3.06137592e-01],\n",
       "         [-6.69084415e-02, -7.67600313e-02,  2.66995847e-01, ...,\n",
       "          -2.24296138e-01, -3.05395782e-01, -1.71482548e-01],\n",
       "         [ 9.09346342e-02, -2.66559888e-04,  3.77010375e-01, ...,\n",
       "          -3.62160504e-01,  3.27988505e-01,  1.41978279e-01]],\n",
       "        shape=(32, 32), dtype=float32)>,\n",
       "  'b4': <tf.Variable 'Variable:0' shape=(32,) dtype=float32, numpy=\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        dtype=float32)>},\n",
       " 'layer5': {'W5': <tf.Variable 'Variable:0' shape=(32, 16) dtype=float32, numpy=\n",
       "  array([[-0.40965858, -0.05940395, -0.07906011, -0.2896399 ,  0.30766276,\n",
       "          -0.28315222, -0.39538398, -0.04464974, -0.16540955,  0.41666833,\n",
       "           0.38191864, -0.10545307, -0.35603464, -0.23325297,  0.1884751 ,\n",
       "           0.4147114 ],\n",
       "         [-0.3229792 , -0.25091296,  0.40107283, -0.16606916,  0.3473195 ,\n",
       "           0.17990091, -0.2383022 , -0.34027216,  0.33429697,  0.16218951,\n",
       "           0.42945915, -0.33383715, -0.12653814,  0.12236735, -0.18840289,\n",
       "           0.2889992 ],\n",
       "         [ 0.2753998 ,  0.1827983 , -0.40620327,  0.35559568, -0.05261977,\n",
       "           0.17437546, -0.07216585,  0.02873522, -0.12700564,  0.00090541,\n",
       "          -0.22683768, -0.1471894 , -0.01074468, -0.25036126,  0.34492436,\n",
       "          -0.32700732],\n",
       "         [-0.16035657, -0.15257409, -0.27868748,  0.39047134, -0.18868747,\n",
       "          -0.2778782 , -0.28282496,  0.26396906, -0.14050794, -0.07836389,\n",
       "           0.16159022,  0.3655761 , -0.36698127, -0.26262885, -0.27827206,\n",
       "           0.21622595],\n",
       "         [ 0.11770803,  0.27071255, -0.43147746, -0.29326162, -0.02309828,\n",
       "           0.12269247,  0.18257955,  0.09123852, -0.10730885, -0.41020924,\n",
       "          -0.19852777, -0.33850187,  0.3705362 ,  0.39563978,  0.07589837,\n",
       "           0.36662886],\n",
       "         [ 0.07028709, -0.03186238,  0.22975388, -0.1554391 ,  0.39111578,\n",
       "           0.00856466,  0.28509864,  0.19984715,  0.1691259 ,  0.07668264,\n",
       "          -0.21926402, -0.11558194, -0.05883367, -0.04799549, -0.18310584,\n",
       "           0.04868685],\n",
       "         [ 0.02776955, -0.22019102, -0.26881042,  0.37373304,  0.06794981,\n",
       "          -0.4162544 , -0.02001164, -0.04118033, -0.01139331, -0.23328355,\n",
       "           0.38533005, -0.29393286,  0.33637887, -0.28623137, -0.4027051 ,\n",
       "          -0.3429426 ],\n",
       "         [ 0.40429497, -0.11311381,  0.0170066 ,  0.00582354,  0.26754877,\n",
       "          -0.24089277, -0.06695633,  0.35361236,  0.17249316, -0.22197904,\n",
       "           0.17579125,  0.2924487 , -0.09935461, -0.03369028,  0.16970044,\n",
       "          -0.15959461],\n",
       "         [-0.16184501,  0.17431033,  0.28686032,  0.04708412, -0.13784614,\n",
       "           0.1827592 , -0.1835636 , -0.38484377,  0.10250238, -0.4302381 ,\n",
       "           0.12748295, -0.08576865,  0.03766255, -0.18346584,  0.12706375,\n",
       "           0.3000081 ],\n",
       "         [-0.10098753,  0.03147989,  0.42379108,  0.03445284, -0.26730207,\n",
       "           0.05107772, -0.19271758, -0.3991899 , -0.21749644, -0.41692713,\n",
       "          -0.340222  , -0.10588124, -0.10772643,  0.21735725, -0.40688562,\n",
       "          -0.23247297],\n",
       "         [-0.33695683, -0.26094848,  0.2110832 , -0.02894867,  0.06139126,\n",
       "           0.24372646, -0.316422  , -0.24254568,  0.00579598, -0.18075983,\n",
       "          -0.21673357,  0.38453248, -0.22175945,  0.35650826,  0.19285205,\n",
       "          -0.15432084],\n",
       "         [-0.419711  , -0.26941645,  0.07301874,  0.365751  ,  0.03616253,\n",
       "           0.22863905, -0.01918478,  0.18821082, -0.3819716 ,  0.09711681,\n",
       "          -0.15623935,  0.2941773 , -0.4231527 , -0.31056288,  0.33156088,\n",
       "          -0.2798399 ],\n",
       "         [ 0.12865153,  0.39331323,  0.10664857, -0.03590617, -0.0650994 ,\n",
       "           0.3101531 , -0.41423306,  0.36459833,  0.1346272 ,  0.3232722 ,\n",
       "           0.17412338, -0.04025566,  0.19578971,  0.2650486 , -0.42842585,\n",
       "          -0.1316632 ],\n",
       "         [ 0.28320202,  0.2201    ,  0.11966773,  0.34529787, -0.33385113,\n",
       "           0.43036357,  0.23938519,  0.35161608,  0.39815158, -0.35824645,\n",
       "          -0.025324  , -0.24940582,  0.12489317,  0.099848  , -0.25867248,\n",
       "           0.4318486 ],\n",
       "         [-0.35369232,  0.10810261, -0.1697866 ,  0.22945154, -0.17247596,\n",
       "          -0.12563363,  0.04445739, -0.04690663, -0.05993975,  0.00142167,\n",
       "          -0.2567045 ,  0.3693315 , -0.16570644, -0.07827057, -0.19245271,\n",
       "           0.26073235],\n",
       "         [ 0.22089985, -0.2595744 , -0.08544508,  0.17745227, -0.39559352,\n",
       "          -0.26068324, -0.33912897, -0.02165008,  0.08517691,  0.33766276,\n",
       "           0.3680774 ,  0.39133394, -0.36091116,  0.04673186, -0.05252977,\n",
       "           0.2432278 ],\n",
       "         [ 0.4140296 ,  0.30466738,  0.15707405,  0.15061308, -0.05601754,\n",
       "          -0.30073228,  0.41263497, -0.33801198, -0.07703144,  0.43103334,\n",
       "          -0.31018618,  0.06590317,  0.3925745 , -0.1550517 , -0.21836038,\n",
       "          -0.42345116],\n",
       "         [-0.4073711 ,  0.37141916, -0.04020971, -0.20866436, -0.3397306 ,\n",
       "           0.21072659,  0.24912369,  0.39993912, -0.22033657, -0.09414795,\n",
       "          -0.42153937, -0.35705364, -0.23548357, -0.42794585,  0.42921114,\n",
       "          -0.01566839],\n",
       "         [ 0.27579337, -0.02625665, -0.4125123 , -0.01316521,  0.06867091,\n",
       "           0.17340563,  0.16514157,  0.14007075, -0.28084522, -0.15148059,\n",
       "          -0.06831182,  0.05867393,  0.4145738 , -0.30539206,  0.20490995,\n",
       "          -0.06925964],\n",
       "         [ 0.25125173, -0.22657502,  0.08702285, -0.02960269,  0.3917207 ,\n",
       "          -0.28505892,  0.341485  , -0.34830603,  0.3653624 , -0.03587065,\n",
       "           0.11833891, -0.21368141,  0.3972039 ,  0.40258518, -0.20122454,\n",
       "           0.3051193 ],\n",
       "         [-0.11020234,  0.36490017, -0.30510855,  0.24426866, -0.26615748,\n",
       "          -0.097862  ,  0.2842239 , -0.36567336, -0.16994843,  0.37097293,\n",
       "           0.1803032 , -0.0759363 , -0.38272142, -0.22773416, -0.42261332,\n",
       "           0.08450754],\n",
       "         [ 0.24342288, -0.18620512, -0.35732996,  0.07080075,  0.36281815,\n",
       "          -0.14759429,  0.34239063, -0.33686808,  0.3052386 ,  0.02958583,\n",
       "           0.09016339,  0.04234289, -0.02017034, -0.3902103 , -0.2968664 ,\n",
       "          -0.29963237],\n",
       "         [-0.4084949 ,  0.09861957,  0.39278385, -0.19692773, -0.43024004,\n",
       "           0.21745405, -0.1955801 ,  0.1465668 ,  0.3884149 ,  0.04125634,\n",
       "           0.00073823,  0.3352712 ,  0.09405953,  0.4103494 , -0.1162632 ,\n",
       "           0.38622797],\n",
       "         [ 0.2101281 ,  0.11308095, -0.02073245,  0.14018638,  0.4241548 ,\n",
       "          -0.42085648,  0.1147449 ,  0.33270058, -0.2678756 ,  0.28976488,\n",
       "           0.38339996,  0.09531853,  0.35116687, -0.30259675, -0.41322577,\n",
       "           0.0650445 ],\n",
       "         [ 0.03684864,  0.28936014,  0.11432454, -0.41314763, -0.36708373,\n",
       "          -0.09279647, -0.13572125,  0.37408078,  0.24672724,  0.42455912,\n",
       "           0.15070373, -0.17626789, -0.25165272, -0.05678284, -0.3834542 ,\n",
       "          -0.03277716],\n",
       "         [ 0.34766138,  0.370574  ,  0.23686606, -0.38187122, -0.30191797,\n",
       "           0.05078019, -0.2099942 , -0.05241939,  0.0173881 , -0.2716892 ,\n",
       "           0.21391566, -0.08122364,  0.32092682,  0.3194553 ,  0.07749644,\n",
       "          -0.36825722],\n",
       "         [ 0.12824337, -0.11143897, -0.24255493,  0.00483779, -0.39989108,\n",
       "          -0.36487707, -0.24012941,  0.36865494, -0.36722374,  0.16452262,\n",
       "           0.04796978,  0.09480433,  0.2193685 , -0.2455785 , -0.23811051,\n",
       "           0.31791556],\n",
       "         [-0.25467566, -0.32702532,  0.09466982, -0.32290438, -0.07647243,\n",
       "          -0.39929926, -0.33062854, -0.1646263 ,  0.02568948,  0.16902082,\n",
       "           0.063973  ,  0.01595157,  0.23232292, -0.4128258 , -0.3830613 ,\n",
       "          -0.02096794],\n",
       "         [-0.08308388, -0.09976844, -0.22416863,  0.10217095,  0.0030115 ,\n",
       "          -0.15588866,  0.21579687, -0.01000265,  0.11587331, -0.1639482 ,\n",
       "           0.03754965, -0.06814182, -0.40866426, -0.3825861 , -0.32702434,\n",
       "           0.0979182 ],\n",
       "         [ 0.0405949 ,  0.29417062, -0.4258436 , -0.30911747, -0.282813  ,\n",
       "          -0.40641648,  0.02822032,  0.3956028 ,  0.14110014,  0.24448074,\n",
       "          -0.1956843 , -0.21248831,  0.21526049, -0.22775427,  0.16361123,\n",
       "           0.35005245],\n",
       "         [-0.36860275, -0.14193502,  0.34687608,  0.36344752, -0.4290282 ,\n",
       "          -0.4022635 ,  0.39317188,  0.33114743,  0.3260877 ,  0.13766588,\n",
       "          -0.3551543 ,  0.3876965 ,  0.17482579,  0.08339957, -0.04021546,\n",
       "           0.19707635],\n",
       "         [ 0.02598113,  0.04354519,  0.31518164,  0.25842738, -0.2495135 ,\n",
       "           0.282092  ,  0.03796653, -0.3877679 , -0.05880069, -0.00722733,\n",
       "          -0.39796227,  0.18036789, -0.15517475,  0.05315288, -0.2813798 ,\n",
       "           0.29648095]], dtype=float32)>,\n",
       "  'b5': <tf.Variable 'Variable:0' shape=(16,) dtype=float32, numpy=\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        dtype=float32)>},\n",
       " 'layer6': {'W6': <tf.Variable 'Variable:0' shape=(16, 8) dtype=float32, numpy=\n",
       "  array([[ 0.37721115, -0.29938123, -0.32035664, -0.26994297,  0.35485968,\n",
       "           0.4719037 , -0.35082746, -0.32026446],\n",
       "         [ 0.2227894 , -0.47420713,  0.51638156,  0.5905515 ,  0.43519425,\n",
       "           0.23402822, -0.6000187 , -0.50796056],\n",
       "         [-0.49891797, -0.05622239,  0.09454682,  0.02593038, -0.13317268,\n",
       "           0.2127462 , -0.07717679,  0.5220417 ],\n",
       "         [-0.43046317, -0.4764917 , -0.56342906, -0.21009083, -0.47947553,\n",
       "          -0.40783572, -0.52650785,  0.4168871 ],\n",
       "         [-0.2637861 , -0.14195485, -0.42264992,  0.55269986,  0.5406649 ,\n",
       "          -0.374154  , -0.40075523,  0.5622772 ],\n",
       "         [-0.41507304,  0.18632428,  0.4382726 , -0.5937055 , -0.316894  ,\n",
       "          -0.45172825, -0.5670751 ,  0.14120007],\n",
       "         [-0.5549805 , -0.18355714,  0.47199664,  0.34063122,  0.11987538,\n",
       "           0.30725655,  0.37723595, -0.36198053],\n",
       "         [-0.23220333,  0.3960143 ,  0.4227826 ,  0.49478754, -0.16411217,\n",
       "          -0.03909442,  0.03780751,  0.3456247 ],\n",
       "         [-0.16388893,  0.14918914, -0.5350712 , -0.55532616,  0.3093317 ,\n",
       "          -0.54872   ,  0.5969544 , -0.35499856],\n",
       "         [ 0.02238813, -0.15690611,  0.11859415, -0.50158113,  0.33411542,\n",
       "          -0.29833844, -0.32814917,  0.53421855],\n",
       "         [-0.24580213, -0.54305726, -0.34839857,  0.42630562,  0.45947507,\n",
       "           0.41573033,  0.35097617, -0.5817279 ],\n",
       "         [ 0.38425827, -0.10698301,  0.5848361 , -0.14367187,  0.14565928,\n",
       "           0.5497248 ,  0.21822092,  0.06152846],\n",
       "         [-0.2202303 ,  0.1806877 , -0.05899977, -0.1529902 , -0.02161696,\n",
       "          -0.01885568, -0.2610547 , -0.28413758],\n",
       "         [ 0.5254643 ,  0.22582327, -0.04940348,  0.15944554,  0.43180093,\n",
       "          -0.5736407 , -0.4193747 , -0.57266384],\n",
       "         [ 0.22076063, -0.5100456 , -0.09003074,  0.43525127, -0.08561249,\n",
       "          -0.02811856,  0.61145097,  0.05061732],\n",
       "         [-0.11765736,  0.49027324,  0.585647  , -0.32054952,  0.10995852,\n",
       "           0.09425511,  0.05717194,  0.2267965 ]], dtype=float32)>,\n",
       "  'b6': <tf.Variable 'Variable:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>},\n",
       " 'layer7': {'W7': <tf.Variable 'Variable:0' shape=(8, 4) dtype=float32, numpy=\n",
       "  array([[-0.3828049 ,  0.26188868, -0.48293194,  0.63965267],\n",
       "         [-0.8448809 ,  0.37572992, -0.2714538 ,  0.55229217],\n",
       "         [-0.70627934, -0.18166548, -0.73489267, -0.62762743],\n",
       "         [ 0.02696409,  0.37447894, -0.23573183, -0.6167721 ],\n",
       "         [ 0.28014937, -0.29224068,  0.0796696 ,  0.58291566],\n",
       "         [-0.4993789 ,  0.10763788, -0.01029984,  0.47076494],\n",
       "         [-0.07432971,  0.27221784,  0.5922724 ,  0.32205054],\n",
       "         [-0.0904402 ,  0.7301671 ,  0.21523304,  0.5813844 ]],\n",
       "        dtype=float32)>,\n",
       "  'b7': <tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>},\n",
       " 'layer8': {'W8': <tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
       "  array([[-0.94602543,  0.03361827,  0.02898698],\n",
       "         [ 0.81078774, -0.12334577,  1.1466117 ],\n",
       "         [-1.074111  ,  1.0380969 ,  1.0478412 ],\n",
       "         [ 0.7122519 , -0.81386185,  0.81345856]], dtype=float32)>,\n",
       "  'b8': <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualización de los pesos y sesgos\n",
    "modelo.weights_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1b6175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(14.657627, shape=(), dtype=float32)\n",
      "tf.Tensor(6.8878007, shape=(), dtype=float32)\n",
      "tf.Tensor(6.469496, shape=(), dtype=float32)\n",
      "tf.Tensor(3.8984947, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9036688, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4624748, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2026707, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1264706, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1646495, shape=(), dtype=float32)\n",
      "tf.Tensor(0.94659245, shape=(), dtype=float32)\n",
      "tf.Tensor(0.85516536, shape=(), dtype=float32)\n",
      "tf.Tensor(0.70658636, shape=(), dtype=float32)\n",
      "tf.Tensor(0.770225, shape=(), dtype=float32)\n",
      "tf.Tensor(0.70571315, shape=(), dtype=float32)\n",
      "tf.Tensor(0.61420983, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8452449, shape=(), dtype=float32)\n",
      "tf.Tensor(0.646573, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5422067, shape=(), dtype=float32)\n",
      "tf.Tensor(0.56378925, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5497764, shape=(), dtype=float32)\n",
      "tf.Tensor(0.60967827, shape=(), dtype=float32)\n",
      "tf.Tensor(0.53869444, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48609635, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4825032, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44432238, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5003195, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45819825, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40123415, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27833512, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39193526, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4584453, shape=(), dtype=float32)\n",
      "tf.Tensor(0.38944542, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4147352, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4655439, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29984236, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4439054, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34356958, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20925938, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4319205, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32596093, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30114338, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5510539, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2797126, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2469278, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19143265, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24452437, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2548408, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75371796, shape=(), dtype=float32)\n",
      "tf.Tensor(0.51812124, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22711276, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45823225, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42227164, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17875372, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29121748, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3125049, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20801942, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29268864, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18237126, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2085481, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2635313, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24357998, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20079812, shape=(), dtype=float32)\n",
      "tf.Tensor(0.26326165, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14219071, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15399605, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18704626, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12888895, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3420531, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13842958, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12231938, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19918343, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23088047, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21430959, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16595721, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12510875, shape=(), dtype=float32)\n",
      "tf.Tensor(0.306107, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1852665, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17668375, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1561162, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22328517, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14868152, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14685148, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15392636, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12451498, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16580994, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13984102, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15414774, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13945067, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13638824, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10491437, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15120593, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2358627, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24185136, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17614545, shape=(), dtype=float32)\n",
      "tf.Tensor(0.098941706, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27144974, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1655766, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10707937, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22321206, shape=(), dtype=float32)\n",
      "tf.Tensor(0.121519305, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento del modelo\n",
    "modelo.fit((X, Y_noisy), epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e3d4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer1': {'W1': <tf.Variable 'Variable:0' shape=(3, 64) dtype=float32, numpy=\n",
       "  array([[ 1.1803852e+00, -6.5378942e-02,  2.5189474e-01, -4.1808441e-01,\n",
       "          -4.6977994e-01, -2.5429267e-01, -8.9089102e-01, -9.4205242e-01,\n",
       "          -1.9440936e-01,  4.3973723e-01, -7.2235274e-01,  6.2674439e-01,\n",
       "           5.6435162e-01,  1.9857439e-01,  8.6488175e-01, -8.4579915e-01,\n",
       "          -7.4498069e-01,  9.9880320e-01,  1.1875346e+00, -8.5321873e-01,\n",
       "           6.7753565e-01, -1.2554756e+00, -6.0209614e-01, -9.1027784e-01,\n",
       "          -4.5592895e-01, -8.6076409e-02,  9.1446143e-01,  7.0466250e-02,\n",
       "          -1.1686658e+00, -5.4466462e-01, -1.0948924e+00, -1.1006112e+00,\n",
       "          -3.2059953e-01,  5.7331108e-02, -4.3615785e-01, -8.9713460e-01,\n",
       "          -6.5962845e-01,  5.3551561e-01, -1.8168369e-01, -8.6528355e-01,\n",
       "           9.9105656e-02, -6.9640911e-01, -4.5692304e-01, -5.8987594e-01,\n",
       "           8.9469299e-02, -5.2062237e-01,  1.1627138e+00, -3.0624318e-01,\n",
       "          -6.5601087e-01,  3.2602990e-01, -1.9097783e-02,  9.1089141e-01,\n",
       "          -7.3334146e-01,  4.0561801e-01,  6.6714990e-01,  3.5091512e-02,\n",
       "           7.1631275e-02,  3.8236487e-01, -5.4402035e-01,  1.0518453e+00,\n",
       "           1.2652826e-01,  6.1274284e-01, -2.1187046e-01,  1.2238071e-01],\n",
       "         [-6.1604822e-01, -6.2408930e-01,  3.5575300e-01,  8.9255315e-01,\n",
       "          -8.4214950e-01, -8.4258074e-01, -9.1484326e-01, -1.0746325e-01,\n",
       "           8.2288557e-01, -6.5864831e-01, -4.4768715e-01, -8.4933043e-02,\n",
       "           4.4639796e-01, -4.9595642e-01, -4.8472926e-01, -4.6883706e-02,\n",
       "          -3.8548103e-01, -3.7946230e-01,  5.1813185e-01,  5.2874100e-01,\n",
       "          -6.9865018e-01,  5.3594675e-02,  3.6594322e-01,  5.9409678e-01,\n",
       "          -1.1012388e+00,  7.8482127e-01, -5.2275240e-01,  5.5721843e-01,\n",
       "           4.2911705e-01,  7.8671730e-01,  3.2509848e-01, -1.1993494e+00,\n",
       "           1.8766153e-01, -3.6689284e-01,  6.9299066e-01, -5.6245494e-01,\n",
       "          -7.9229176e-02,  5.7248205e-01, -4.2303532e-01,  4.0363657e-01,\n",
       "           3.1938791e-01,  2.8713262e-01,  7.2924596e-01, -1.9587931e-01,\n",
       "          -9.7788203e-01, -4.2515621e-01, -3.8894144e-01, -5.6486952e-01,\n",
       "           1.0023922e-01, -8.5174376e-01, -9.5633161e-01,  1.0348364e+00,\n",
       "           6.1972052e-01, -6.5811795e-01, -3.0177531e-01,  7.1872860e-01,\n",
       "          -1.7952656e-02, -7.0532417e-01, -2.4459604e-02,  8.3461744e-01,\n",
       "          -6.4376462e-01,  1.3574333e+00, -4.9090765e-02, -6.6188258e-01],\n",
       "         [ 7.5892955e-01, -6.3201809e-01,  9.6886205e-03, -1.6843887e-01,\n",
       "          -3.8659942e-01,  1.0126050e+00,  3.6678791e-01, -4.9638039e-01,\n",
       "          -9.1476542e-01, -1.0085741e+00,  3.1132174e-01, -7.7748477e-01,\n",
       "           1.7405744e-01,  8.4539932e-01,  6.1424839e-01, -9.3479460e-01,\n",
       "           2.6328443e-04, -2.2242244e-01, -1.9413304e-01,  8.1366435e-02,\n",
       "          -1.6892555e-01,  3.3309069e-01, -3.2787731e-01, -8.6159229e-02,\n",
       "          -3.2520479e-01, -7.9334354e-01,  3.4820312e-01, -1.9064203e-01,\n",
       "           1.0745356e+00,  5.1139498e-01, -5.0073195e-01, -1.6225733e-01,\n",
       "           6.8728352e-01,  9.9037729e-02, -1.1418947e+00,  3.5726807e-01,\n",
       "          -7.5851895e-02,  7.6759374e-01,  2.4274306e-01,  1.1234442e+00,\n",
       "           5.4037583e-01,  1.0116684e+00, -3.9514899e-01, -2.2915915e-01,\n",
       "          -1.0130842e+00,  7.4099660e-01, -3.3896789e-01,  1.0194484e-01,\n",
       "           2.6606910e-02,  6.5496629e-01, -2.5887308e-01, -8.7765145e-01,\n",
       "          -2.5096479e-01, -1.1383940e+00, -3.5731621e-02,  5.9149317e-02,\n",
       "          -1.1760316e+00,  1.2620962e+00,  2.1390831e-01, -3.5140496e-01,\n",
       "           7.3696756e-01, -6.7074740e-01, -5.9995866e-01,  1.0378331e+00]],\n",
       "        dtype=float32)>,\n",
       "  'b1': <tf.Variable 'Variable:0' shape=(64,) dtype=float32, numpy=\n",
       "  array([-0.5307417 , -0.34664872, -0.27124542, -0.13859537,  0.14456536,\n",
       "         -0.8181449 , -0.2241126 , -0.14879383, -0.46024436, -0.44611108,\n",
       "         -0.5871112 , -0.42049995, -0.28188533, -0.39114088, -0.5460606 ,\n",
       "         -0.24687563, -0.60146576, -0.07398829, -0.58281285, -0.4648729 ,\n",
       "         -0.7948813 , -0.25965708, -0.43825504, -0.31272796, -0.26595634,\n",
       "         -0.43713358, -0.63342667, -0.36893803, -0.35375324, -0.43288904,\n",
       "         -0.5959232 , -0.04182816, -0.34505436, -0.46211988, -0.15291475,\n",
       "         -0.7331811 , -0.2150073 , -0.31149778, -0.33566943, -0.45050788,\n",
       "         -0.4381963 , -0.48885053, -0.27069893,  0.3238729 , -0.2779838 ,\n",
       "         -0.30092928,  0.00531599,  0.0038539 , -0.22947767, -0.29658976,\n",
       "         -0.6774282 , -0.2975922 , -0.47758856, -0.33836347, -0.30957612,\n",
       "         -0.37375075, -0.25010863, -0.48522392, -0.26403514, -0.11485576,\n",
       "         -0.632959  , -0.13791487, -0.416334  , -0.63050747], dtype=float32)>},\n",
       " 'layer2': {'W2': <tf.Variable 'Variable:0' shape=(64, 64) dtype=float32, numpy=\n",
       "  array([[-0.08970685,  0.0639365 , -0.22219008, ..., -0.05683968,\n",
       "           0.3804804 ,  0.05929736],\n",
       "         [ 0.3234034 , -0.02602133,  0.19681326, ..., -0.1484673 ,\n",
       "          -0.19830567, -0.71825093],\n",
       "         [-0.21717888,  0.0394331 , -0.01722113, ..., -0.12323391,\n",
       "           0.04561462,  0.06202418],\n",
       "         ...,\n",
       "         [-0.44293162, -0.13766786, -0.44411343, ..., -0.37793145,\n",
       "          -0.360719  ,  0.04746842],\n",
       "         [-0.01272361,  0.08173623, -0.03301399, ..., -0.19811592,\n",
       "          -0.15362492, -0.14046088],\n",
       "         [ 0.29949656,  0.04447437, -0.5192018 , ..., -0.414771  ,\n",
       "           0.15205666, -0.18621814]], shape=(64, 64), dtype=float32)>,\n",
       "  'b2': <tf.Variable 'Variable:0' shape=(64,) dtype=float32, numpy=\n",
       "  array([-0.17847148, -0.32690743, -0.23647031, -0.50298876,  0.12803268,\n",
       "          0.09995618,  0.11217634,  0.04002726,  0.21924794,  0.06786244,\n",
       "         -0.26311892, -0.42343664, -0.40421948, -0.04895173,  0.02238729,\n",
       "          0.57396144, -0.5315534 ,  0.1010444 , -0.09696221, -0.47738647,\n",
       "          0.20480278, -0.10493672,  0.31636378,  0.02719689, -0.27149284,\n",
       "          0.09224015,  0.16890167, -0.10186797,  0.02764207, -0.14841399,\n",
       "         -0.17827165, -0.64668125, -0.40796804, -0.17685992, -0.59276855,\n",
       "         -0.41221955, -0.43877906,  0.07563097, -0.25990495, -0.45512798,\n",
       "         -0.1797837 , -0.01652331, -0.2568745 , -0.2570054 , -0.2988575 ,\n",
       "          0.3818544 , -0.53310734, -0.43617484, -0.06284555,  0.12169044,\n",
       "         -0.5065478 , -0.08460654, -0.42330158, -0.1304626 , -0.09042992,\n",
       "         -0.20451593, -0.06511749, -0.17012411,  0.3189182 , -0.72140086,\n",
       "          0.18644719, -0.00796956, -0.21594603, -0.1595911 ], dtype=float32)>},\n",
       " 'layer3': {'W3': <tf.Variable 'Variable:0' shape=(64, 32) dtype=float32, numpy=\n",
       "  array([[-0.06099379, -0.4076285 , -0.20792365, ...,  0.25059578,\n",
       "          -0.4251577 ,  0.22928913],\n",
       "         [ 0.08049027, -0.06984381,  0.30800042, ...,  0.07537948,\n",
       "          -0.10613003, -0.06172062],\n",
       "         [-0.38076818,  0.10930204,  0.01473744, ...,  0.07189295,\n",
       "           0.06209478,  0.19132474],\n",
       "         ...,\n",
       "         [-0.1978718 ,  0.05262287, -0.06692633, ..., -0.31818622,\n",
       "          -0.73022383, -0.37164176],\n",
       "         [-0.36367583, -0.1420458 ,  0.37162864, ...,  0.08482296,\n",
       "           0.10439488, -0.3067797 ],\n",
       "         [ 0.55964696, -0.27037454,  0.27261406, ..., -0.05643902,\n",
       "           0.06636164,  0.2457375 ]], shape=(64, 32), dtype=float32)>,\n",
       "  'b3': <tf.Variable 'Variable:0' shape=(32,) dtype=float32, numpy=\n",
       "  array([ 0.07662605, -0.15568258, -0.3883964 , -0.25720054, -0.38318276,\n",
       "          0.1013675 , -0.20587397, -0.11079074, -0.28740856, -0.26186967,\n",
       "         -0.00767663,  0.21019441, -0.5339343 , -0.17437015, -0.53708327,\n",
       "         -0.18948078,  0.06529365, -0.6342664 ,  0.2516218 ,  0.0625771 ,\n",
       "         -0.20564717,  0.10068576, -0.11816403, -0.2950982 , -0.24832648,\n",
       "         -0.27531338,  0.00221285,  0.3145409 , -0.22134458, -0.01581227,\n",
       "         -0.28327444, -0.23883203], dtype=float32)>},\n",
       " 'layer4': {'W4': <tf.Variable 'Variable:0' shape=(32, 32) dtype=float32, numpy=\n",
       "  array([[ 0.07780162, -0.65552735,  0.42126688, ..., -0.19328749,\n",
       "           0.22918147, -0.33629903],\n",
       "         [-0.35439616,  0.275173  ,  0.37041298, ...,  0.21499807,\n",
       "          -0.370199  ,  0.20706983],\n",
       "         [-0.02811859, -0.31705517, -0.36140457, ..., -0.26307732,\n",
       "          -0.2787436 , -0.3012182 ],\n",
       "         ...,\n",
       "         [-0.24286959,  0.21284953,  0.36130318, ..., -0.27566043,\n",
       "           0.58241475, -0.3910574 ],\n",
       "         [-0.24687895, -0.1963076 ,  0.6581465 , ..., -0.34675452,\n",
       "          -0.7056232 , -0.29601073],\n",
       "         [-0.27644643,  0.09549863,  0.44009522, ..., -0.64346635,\n",
       "          -0.03121167, -0.13810243]], shape=(32, 32), dtype=float32)>,\n",
       "  'b4': <tf.Variable 'Variable:0' shape=(32,) dtype=float32, numpy=\n",
       "  array([-0.19193925, -0.12741502, -0.25262517, -0.00995459, -0.34586614,\n",
       "          0.08636867, -0.53854567,  0.05487581,  0.05991632,  0.20289862,\n",
       "         -0.18195823,  0.13690539, -0.2233348 , -0.01903817, -0.81455326,\n",
       "         -0.29827946, -0.4913413 ,  0.18884468, -0.39647424, -0.3663874 ,\n",
       "         -0.4078965 , -0.55366266,  0.08015539,  0.01514669, -0.48625103,\n",
       "         -0.2673332 ,  0.42523944,  0.12207461, -0.13134399,  0.23637079,\n",
       "          0.2665046 ,  0.00637783], dtype=float32)>},\n",
       " 'layer5': {'W5': <tf.Variable 'Variable:0' shape=(32, 16) dtype=float32, numpy=\n",
       "  array([[-0.10277347,  0.3918969 , -0.2766341 , -0.03289248,  0.7236253 ,\n",
       "           0.28377193, -0.54623365, -0.13473243, -0.15724528,  0.5005309 ,\n",
       "           0.14652866, -0.39003628, -0.25634587,  0.1880657 , -0.15648037,\n",
       "           0.4101088 ],\n",
       "         [-0.34032837, -0.17113844,  0.31538072, -0.3609749 ,  0.20615661,\n",
       "           0.16910164, -0.45431077, -0.1672355 ,  0.31810144,  0.35740632,\n",
       "           0.32698697, -0.3654646 , -0.49075738, -0.02141322,  0.35554788,\n",
       "           0.21851091],\n",
       "         [ 0.4917304 ,  0.26293015, -0.5960441 ,  0.04896433,  0.02522865,\n",
       "           0.6213306 ,  0.08515122, -0.06715931, -0.11589012,  0.31846276,\n",
       "          -0.0133984 , -0.18156773,  0.278274  ,  0.40243834,  0.35573986,\n",
       "          -0.60479707],\n",
       "         [ 0.01003324, -0.15663755, -0.11682467,  0.35165903, -0.2144442 ,\n",
       "          -0.5404945 , -0.3686499 ,  0.300623  , -0.9514927 ,  0.07772876,\n",
       "           0.23819217,  0.4320844 , -0.4731252 , -0.36986193,  0.43400553,\n",
       "           0.20041956],\n",
       "         [ 0.0440044 ,  0.32940096, -0.39387798, -0.2424792 ,  0.04469912,\n",
       "           0.25198063,  0.06392511, -0.00656715, -0.14897898, -0.19821492,\n",
       "          -0.5636918 , -0.07336846,  0.1415191 ,  0.59439623,  0.13285038,\n",
       "           0.5172949 ],\n",
       "         [ 0.06746029, -0.051729  ,  0.18315098, -0.510296  ,  0.21762784,\n",
       "          -0.1637221 ,  0.13827606,  0.11100209,  0.1235897 , -0.00314317,\n",
       "          -0.20795898, -0.18139344, -0.17139173, -0.23133351,  0.0518581 ,\n",
       "          -0.07547861],\n",
       "         [-0.00822078, -0.06150367, -0.07995989,  0.43348303,  0.32916415,\n",
       "          -0.2742352 , -0.36988395, -0.41714343,  0.10851345,  0.47731763,\n",
       "           0.06776159, -0.29212156, -0.17185225, -0.33091876, -0.04208138,\n",
       "          -0.6507343 ],\n",
       "         [ 0.31099352, -0.32664812,  0.20567554, -0.46727228, -0.04046305,\n",
       "          -0.48134595, -0.04319584,  0.2740034 ,  0.09347954, -0.5349583 ,\n",
       "           0.33267245,  0.4380186 , -0.18692213, -0.2815143 ,  0.01028828,\n",
       "          -0.84732276],\n",
       "         [ 0.19256571,  0.10516247,  0.39233723, -0.3066424 , -0.0267654 ,\n",
       "          -0.06336281,  0.07713598, -0.3737773 ,  0.25316536, -0.32125267,\n",
       "           0.3062123 , -0.40468693, -0.4393353 , -0.3824674 ,  0.17037326,\n",
       "           0.47207567],\n",
       "         [-0.18772742, -0.13195826,  0.4799651 ,  0.22214995, -0.19308095,\n",
       "           0.10024442, -0.24860592, -0.38469732, -0.3864703 , -0.42219687,\n",
       "          -0.6049566 , -0.48531738, -0.10553525,  0.01556559, -0.3830442 ,\n",
       "          -0.31128433],\n",
       "         [-0.17319869, -0.02124386,  0.00142552, -0.59826994, -0.01628668,\n",
       "          -0.20259741, -0.05667612, -0.37649736,  0.29148784, -0.32484117,\n",
       "          -0.28994784,  0.54589623, -0.34652996,  0.60112405, -0.0374283 ,\n",
       "          -0.1797873 ],\n",
       "         [-0.32879335, -0.2904775 , -0.00571487,  0.23646961, -0.18006803,\n",
       "           0.11356854, -0.01614065, -0.02987337, -0.33199355, -0.0191991 ,\n",
       "          -0.2034085 ,  0.22872381, -0.41075844, -0.3747772 ,  0.3296122 ,\n",
       "          -0.6776768 ],\n",
       "         [-0.37544993,  0.4184004 , -0.04213673, -0.17898113,  0.17342715,\n",
       "          -0.11849201, -0.22880936,  0.3293683 ,  0.15695006,  0.40012148,\n",
       "           0.5254769 , -0.31773007, -0.28112873,  0.38648662, -0.16982424,\n",
       "          -0.19177082],\n",
       "         [ 0.16709262,  0.25983566,  0.06666127,  0.24390769, -0.13972528,\n",
       "           0.572979  , -0.02881507,  0.32171398,  0.57781494, -0.16000369,\n",
       "          -0.290554  , -0.370409  ,  0.19770525, -0.06893852, -0.20344986,\n",
       "           0.42121866],\n",
       "         [-0.09806349,  0.91115654, -0.19609605,  0.02090055, -0.5919382 ,\n",
       "          -0.03416681, -0.02046137, -0.21204847,  0.32467037,  0.13825564,\n",
       "          -0.10000683,  0.4768744 , -0.1856369 ,  0.30442274, -0.15355094,\n",
       "           0.409542  ],\n",
       "         [ 0.27194983, -0.16971177, -0.23944725, -0.15726675, -0.31128645,\n",
       "          -0.3998996 , -0.09650531, -0.36237514, -0.06091655,  0.16758029,\n",
       "           0.4890184 ,  0.480068  , -0.17027532,  0.05824359, -0.17794213,\n",
       "          -0.28118005],\n",
       "         [ 0.8295286 ,  0.03707753, -0.16984512,  0.11020347, -0.01982403,\n",
       "          -0.12080482,  0.04009036, -0.53284186,  0.00916647,  0.6627702 ,\n",
       "           0.01896117,  0.13230261,  0.19500645, -0.25620142, -0.20365083,\n",
       "          -0.37563047],\n",
       "         [-0.19158123,  0.21961614, -0.26263967, -0.4325779 , -0.5496989 ,\n",
       "           0.646623  ,  0.15486135,  0.29241434,  0.15810485,  0.04646756,\n",
       "          -0.48616877, -0.4196697 , -0.29873094, -0.538623  ,  0.29912794,\n",
       "          -0.23116009],\n",
       "         [-0.05548414,  0.24264559, -0.81409895, -0.41108453,  0.07352735,\n",
       "           0.27147314,  0.3673704 ,  0.20880038, -0.20653148, -0.3552702 ,\n",
       "           0.0207548 ,  0.34362286, -0.02267951, -0.01288908,  0.02436111,\n",
       "          -0.19171467],\n",
       "         [-0.05945499, -0.24907026,  0.16625704, -0.22074181,  0.3865774 ,\n",
       "          -0.514255  ,  0.3449226 , -0.23931985, -0.33996302, -0.03420012,\n",
       "           0.16473578, -0.502902  ,  0.08976658,  0.49191514, -0.17417632,\n",
       "           0.06183186],\n",
       "         [-0.15496565,  0.25246084, -0.5157855 ,  0.32913876, -0.2982047 ,\n",
       "          -0.14976023,  0.2712704 , -0.45968252, -0.22825515,  0.8824515 ,\n",
       "           0.6387546 , -0.10955271, -0.43512857, -0.27390215, -0.39257464,\n",
       "          -0.05337137],\n",
       "         [-0.31105277,  0.08086622, -0.08453237,  0.1949528 ,  0.6217417 ,\n",
       "          -0.65572864, -0.01413272, -0.15663606, -0.19821748,  0.0095957 ,\n",
       "          -0.0460543 ,  0.02805731, -0.30721283, -0.14785096, -0.06471331,\n",
       "          -0.11598504],\n",
       "         [-0.41619748,  0.09270313,  0.33094966, -0.63890535, -0.25778168,\n",
       "           0.12328897, -0.21373269,  0.01630158,  0.10512328,  0.01369173,\n",
       "           0.04056409, -0.02891064, -0.01376938,  0.46131223, -0.31677163,\n",
       "           0.18088849],\n",
       "         [-0.03470131, -0.00795927,  0.02252726,  0.05575996,  0.37634656,\n",
       "          -0.84347516,  0.40289506,  0.25851488,  0.01645575, -0.03512637,\n",
       "           0.19806242,  0.10247038,  0.24081396, -0.5315476 , -0.62584317,\n",
       "          -0.08547776],\n",
       "         [ 0.26439053,  0.35785756,  0.0069786 , -0.43501806, -0.25727382,\n",
       "          -0.37999633, -0.20314983,  0.33021453, -0.09959766, -0.00676223,\n",
       "           0.12909585, -0.64164567, -0.11769889,  0.18192254, -0.68129027,\n",
       "          -0.4727743 ],\n",
       "         [ 0.32633483,  0.01461814,  0.29122746, -0.41242597, -0.1920827 ,\n",
       "          -0.14162801, -0.28551033,  0.35309434,  0.12526084, -0.10531184,\n",
       "           0.31204346,  0.3302712 , -0.18945763,  0.4115836 ,  0.21707942,\n",
       "          -0.46142426],\n",
       "         [-0.12900257, -0.17203093, -0.23405762, -0.11691252, -0.01888932,\n",
       "          -0.5950407 , -0.5129917 ,  0.36183718, -0.31189695,  0.03178348,\n",
       "           0.07829841, -0.17274728, -0.17054403, -0.36720788, -0.496613  ,\n",
       "           0.21819672],\n",
       "         [-0.03755448, -0.53155535,  0.1087702 , -0.40293884,  0.04228624,\n",
       "          -0.6037792 , -0.7752208 , -0.00907787, -0.08579852,  0.26368508,\n",
       "          -0.12215286, -0.2546261 ,  0.31117442, -0.5369348 , -0.25360608,\n",
       "          -0.00156591],\n",
       "         [-0.45940268,  0.05434141, -0.08201645,  0.29798862, -0.31075567,\n",
       "          -0.6458968 ,  0.4233756 ,  0.04968783, -0.33155498, -0.15744892,\n",
       "           0.34063166, -0.07838   , -0.39402434, -0.31986025, -0.16370332,\n",
       "          -0.16730657],\n",
       "         [-0.28731087,  0.3826843 , -0.59660727, -0.22065656, -0.16026975,\n",
       "           0.07423451, -0.03332663,  0.02127363, -0.06952326,  0.37700784,\n",
       "          -0.2423536 , -0.21886513, -0.28646666, -0.02331319,  0.07631619,\n",
       "           0.17456311],\n",
       "         [ 0.41989487, -0.62511045,  0.03322547,  0.23174924, -0.44238475,\n",
       "           0.09101401,  0.7434568 ,  0.02376688,  0.6116593 , -0.22605753,\n",
       "           0.09098458,  0.44229472,  0.720968  ,  0.20947415, -0.08724757,\n",
       "          -0.01297933],\n",
       "         [ 0.17956726,  0.1273492 ,  0.31020096,  0.19106928, -0.0785981 ,\n",
       "           0.13604087, -0.19928394, -0.37496322,  0.09242508, -0.01075023,\n",
       "          -0.6094689 ,  0.17243567, -0.40659666,  0.00181035,  0.2923692 ,\n",
       "           0.2589684 ]], dtype=float32)>,\n",
       "  'b5': <tf.Variable 'Variable:0' shape=(16,) dtype=float32, numpy=\n",
       "  array([-0.56283766, -0.59171563,  0.38692856,  0.0427888 , -0.16709766,\n",
       "         -0.11968417, -0.10030677,  0.3688241 , -0.21588832, -0.33902207,\n",
       "         -0.41536427,  0.13697141, -0.6118192 , -0.42606357,  0.15438446,\n",
       "          0.3416124 ], dtype=float32)>},\n",
       " 'layer6': {'W6': <tf.Variable 'Variable:0' shape=(16, 8) dtype=float32, numpy=\n",
       "  array([[ 0.0338999 , -0.24588127, -0.12332222, -0.3577334 ,  0.48085752,\n",
       "           0.6599956 , -0.34898075,  0.03674543],\n",
       "         [ 1.0870665 , -0.19156528,  0.2221595 ,  0.58270556,  0.2548417 ,\n",
       "           0.1525277 , -0.5088846 , -0.4448911 ],\n",
       "         [-0.6140383 , -0.06972805,  0.07077075,  0.13845335,  0.11289589,\n",
       "           0.14722595, -0.03256615,  0.55629814],\n",
       "         [-0.89375585, -0.8354591 , -0.47726676,  0.12328827, -0.42775014,\n",
       "          -0.5346187 , -1.0459024 ,  0.31644192],\n",
       "         [-0.37466133, -0.34760877, -0.43284285,  0.5352324 ,  0.5420862 ,\n",
       "          -0.27460158, -0.37214273,  0.17343165],\n",
       "         [-0.3930179 , -0.1454726 ,  0.3002166 , -0.6224336 ,  0.06791675,\n",
       "          -0.7103372 , -0.49250802,  0.10907613],\n",
       "         [-0.53613585,  0.01571455,  0.5583625 ,  0.26178914,  0.33684975,\n",
       "           0.65808105,  0.29999048, -0.37966064],\n",
       "         [-0.2870408 ,  0.23403679,  0.4289049 ,  0.58110106, -0.2737207 ,\n",
       "          -0.06719889,  0.04792662,  0.15108436],\n",
       "         [ 0.05370869,  0.5182068 , -0.6025302 , -0.16177891, -0.13019761,\n",
       "          -0.36488843,  0.5750818 , -0.33226073],\n",
       "         [-0.07937176, -0.41176242,  0.29771712, -0.26492706, -0.06156637,\n",
       "          -0.578248  , -0.46869424,  0.47733155],\n",
       "         [-0.28340048, -0.7040117 , -0.09180309,  0.52662176,  0.23248695,\n",
       "           0.46088585,  0.2974961 , -0.7896119 ],\n",
       "         [ 0.26547125, -0.2570141 ,  0.7891103 ,  0.02517604,  0.24945603,\n",
       "           0.6013081 ,  0.21576075,  0.04474944],\n",
       "         [-0.36265156,  0.05275113, -0.00618785, -0.3052643 ,  0.65563637,\n",
       "           0.31880173, -0.45611387,  0.06394576],\n",
       "         [ 0.6268643 ,  0.08090375,  0.03070891,  0.4183821 ,  0.41140017,\n",
       "          -0.42929593, -0.38626596, -0.63806796],\n",
       "         [-0.10626888, -0.28076175,  0.10016914, -0.04263636,  0.05309072,\n",
       "           0.03783757,  0.65210205, -0.06997458],\n",
       "         [ 0.05414999,  0.5251494 ,  0.51229304, -0.07642482, -0.11813685,\n",
       "          -0.04116213,  0.08586972,  0.24160346]], dtype=float32)>,\n",
       "  'b6': <tf.Variable 'Variable:0' shape=(8,) dtype=float32, numpy=\n",
       "  array([ 0.27405703,  0.5264124 , -0.38062957,  0.6948921 , -0.5659423 ,\n",
       "          0.4605649 ,  0.53379977,  0.5355354 ], dtype=float32)>},\n",
       " 'layer7': {'W7': <tf.Variable 'Variable:0' shape=(8, 4) dtype=float32, numpy=\n",
       "  array([[-8.8023168e-01,  7.2626591e-02, -7.3684621e-01,  5.9992582e-01],\n",
       "         [-1.0931150e+00,  4.1720295e-01, -2.1448277e-01,  4.7520867e-01],\n",
       "         [-1.5143255e+00, -6.9087081e-02, -3.5108769e-01, -9.3991375e-01],\n",
       "         [-7.7576321e-01,  4.0953177e-01, -1.3089801e-01, -9.1213828e-01],\n",
       "         [ 5.0635953e-02, -3.8632059e-01,  3.2111421e-02,  4.9794939e-01],\n",
       "         [-1.4624927e+00,  9.2937171e-02,  4.1147792e-01, -7.1176980e-04],\n",
       "         [-1.0454847e+00,  2.3762558e-01,  4.9210504e-01, -9.0131484e-02],\n",
       "         [-9.6494481e-02,  7.5597328e-01,  2.6072964e-01,  4.3418080e-01]],\n",
       "        dtype=float32)>,\n",
       "  'b7': <tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([-0.9487381 ,  0.68618584,  0.3898429 ,  0.27824122], dtype=float32)>},\n",
       " 'layer8': {'W8': <tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
       "  array([[-1.4706844 , -0.7428825 ,  0.48873836],\n",
       "         [ 1.0211527 ,  0.4271787 ,  0.9736701 ],\n",
       "         [-0.92410314,  1.2285752 ,  0.620804  ],\n",
       "         [ 0.06433038, -0.8203796 ,  0.771617  ]], dtype=float32)>,\n",
       "  'b8': <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0.9345371 , 1.1060385 , 0.42764172], dtype=float32)>}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificamos que los pesos realmente hayan cambiado\n",
    "modelo.weights_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d157265",
   "metadata": {},
   "source": [
    "**Errores y como los solucione**\n",
    "\n",
    "`Error donde no actualizaban los pesos y sesgos`: Este error me sucedió cuando antes de usar Adam como optimizador para actualizar pesos, intenté implementarlo solamente con GradientTape puro sin optimizadores, lo cual el problema causado era que no observaba las variables de TensorFlow, aunque pude optar por el método .watch de GradientTape, pensé que sería mejor opción el optimizador ADAM\n",
    "\n",
    "`Problemas con ReLU`: Antes de optar por Leaky ReLU, opté por la función de activación ReLU, pero al pasar los datos por la función, se terminaban haciendo la gran mayoría 0, por lo que no había gradiente y eso optaba por cancelar el gradiente para ese peso de x capa.\n",
    "\n",
    "**Observaciones** \n",
    "\n",
    "`Los pesos utilizan una inicialización He_uniform aplicada con matemáticas`: Para evitar que el gradiente explote o se desvanezca opté por una inicialización con he_uniform para hacerlos más... ¿Cómo decirlo? Apetecibles o que sea más fácil calcular el gradiente, mejor dicho.\n",
    "\n",
    "`Aprendizaje`: Logré aplicar la lógica a muy bajo nivel de cómo funciona Keras y aprender como funciona Keras, aunque también conozco la matemática de CNNs (kernels, mapas de activación, maxpooling, etc.) no quise implementar una CNN y preferí por una red MLP (Multi perceptrones), asi también aprendí a entrenar modelos a mano."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
